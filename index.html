<html>

<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-140332927-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-140332927-3');
    </script>

    <style type="text/css">
        a {
            color: #1772d1;
            text-decoration: none;
            word-wrap: break-word;
            overflow-wrap: break-word;
            -ms-word-break: break-all;
            word-break: break-all;
            word-break: break-word;
            -webkit-hyphens: auto;
            -moz-hyphens: auto;
            hyphens: auto;
        }

        a:focus,
        a:hover {
            color: #f09227;
            text-decoration: none;
        }

        body,
        td,
        th {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 18px;
            color: #000000;
        }

        tr {
            padding: 20px;
            text-align: center;
        }

        strong {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 14px
        }

        heading {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 15px;
            font-weight: 700;
        }

        .section {
            width: 60%;
            min-width: 700px;
            margin: 0 auto;
            text-align: center;
            padding: 1em 1em 1em 1em;
            background: #F5F5F5;
        }

        .section_header {
            font-size: 24px;
            font-weight: 700;
            color: #76b900;
        }

        .table_header {
            background-color: #76b900;
            color: white;
        }

        hr {
            border: 1px solid black;
            margin: 0.2%;
        }

        .lightgreen {
            background-color: #e6f3d1;
        }

        .mildgreen {
            background-color: #75b90077;
        }

        table {
            margin-top: 2%;
            border-collapse: collapse;
            width: 100%;
        }

        table td {
            border: 1px solid black;
            padding: 1%;
            font-size: 16px;
        }

        table tr:first-child td {
            border-top: 0;
        }

        table tr td:first-child {
            border-left: 0;
        }

        table tr:last-child td {
            border-bottom: 0;
        }

        table tr td:last-child {
            border-right: 0;
        }

        mark {
            background-color: rgba(21, 255, 0, 0.61);
            color: black;
        }

        .pic {
            border-radius: 50%;
            width: 100%;
        }

        .noborder,
        .noborder tr,
        .noborder th,
        .noborder td {
            border: none;
        }
    </style>
    <link href='//fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <title>AMP Tutorial</title>
    <link rel="shortcut icon" href="imgs/favicon.ico">
</head>

<body>
    <p align="center" style="padding-top: 3%">
        <font size="5">ICCV 2019 Tutorial on</font></br>
        <font size="6">Accelerating Computer Vision with Mixed Precision</font></br></br>

        <b>Time and Location:</b></br>
        Saturday, Nov 2, Half Day AM</br>
        <a href="imgs/map.png" target="_blank">Room E5</a>
        </br></br>
    </p>


    <div class="section">
        <div class="section_header">Overview</div>
        <p style="text-align: left;">
            New levels of accuracy in computer vision, from image recognition and detection, to generating images with
            GANs, have been achieved by increasing the size of trained models. Fast turn-around times while iterating on
            the design of such models would greatly improve the rate of progress in this new era of computer vision.
            </br>
        </p>

        <p style="text-align: center; background-color: rgba(21, 255, 0, 0.61);">
            This tutorial will describe techniques that utilize half-precision floating point representations to
            allow deep learning practitioners to accelerate the training of large deep networks while also reducing
            memory requirements.</br>
        </p>

        <p style="text-align: left;">
            The talks and sessions below will provide a deep-dive into available software packages that enable easy
            conversion of
            models to mixed precision training, practical application examples and tricks of the trade (mixed precision
            arithmetic, loss scaling, etc.), as well as considerations relevant to training many popular models in
            commonly used deep learning frameworks including <a href="https://pytorch.org/" target="_blank">PyTorch</a>
            and <a href="https://www.tensorflow.org/" target="_blank">TensorFlow</a>.
        </p>


    </div>
    </br>


    <div class="section">
        <div class="section_header">Schedule</div>
        <table align="center">
            <tbody>
                <tr class="table_header">
                    <td><b>Time</b></td>
                    <td><b>Title</b></td>
                    <td><b>Speaker</b></td>
                    <td><b>Affil.</b></td>
                </tr>
                <tr>
                    <td>08:45 - 08:50</td>
                    <td>Welcome</td>
                    <td><a href="https://arunmallya.github.io/" target="_blank">Arun Mallya</a></td>
                    <td>NVIDIA</td>
                </tr>
                <tr>
                    <td>08:50 - 09:30</td>
                    <td>Introduction to Mixed Precision Training with PyTorch and TensorFlow</td>
                    <td>Dusan Stosic</td>
                    <td>NVIDIA</td>
                </tr>
                <tr>
                    <td>09:30 - 10:00</td>
                    <td>Mixed Precision Training and Inference at Scale at Alibaba</td>
                    <td>Jun Yang</td>
                    <td>Alibaba</td>
                </tr>
                <tr>
                    <td>10:00 - 11:00</td>
                    <td>Coffee Break</td>
                    <td></td>
                    <td></td>
                </tr>
                <tr class='mildgreen'>
                    <td colspan=100%>
                        <b>Accelerating Various Tasks with Mixed Precision</b>
                    </td>
                </tr>
                <tr class="lightgreen">
                    <td>11:00 - 11:20</td>
                    <td>Network Pruning</td>
                    <td>Pavlo Molchanov</td>
                    <td>NVIDIA</td>
                </tr>
                <tr>
                    <td>11:20 - 11:35</td>
                    <td>Semantic Segmentation</td>
                    <td>Karan Sapra</td>
                    <td>NVIDIA</td>
                </tr>
                <tr class="lightgreen">
                    <td>11:35 - 11:50</td>
                    <td>Image Processing</td>
                    <td><a href="https://liuguilin1225.github.io/" target="_blank">Guilin Liu</a></td>
                    <td>NVIDIA</td>
                </tr>
                <tr>
                    <td>11:50 - 12:10</td>
                    <td>Image Synthesis</td>
                    <td><a href="https://tcwang0509.github.io/" target="_blank">Ting-Chun Wang</a></td>
                    <td>NVIDIA</td>
                </tr>
                <tr class="lightgreen">
                    <td>12:10 - 12:30</td>
                    <td>Generative Adversarial Networks (GANs)</td>
                    <td><a href="http://mingyuliu.net/" target="_blank">Ming-Yu Liu</a></td>
                    <td>NVIDIA</td>
                </tr>
            </tbody>
        </table>
    </div>
    </br>

    <div class="section">
        <div class="section_header">Useful Links</div>
        </br>
        <div style="text-align: left;">
            <b>NVIDIA Tensor Cores for Mixed Precision:</b>
            <a target="_blank" href="https://developer.nvidia.com/tensor-cores">Discover, Learn, Test, and Implement</a>
            /
            <a target="_blank" href="https://devblogs.nvidia.com/optimizing-gpu-performance-tensor-cores/">Optimizing
                for Tensor Cores</a>
            </br> </br>

            <b>High-Performance Sample Code for Various Applications:</b>
            <a target="_blank" href="https://github.com/NVIDIA/DeepLearningExamples">PyTorch and TensorFlow</a>
            </br> </br>

            <b>NVIDIA Automatic Mixed Precision (AMP):</b>
            <a target="_blank" href="https://github.com/NVIDIA/apex/tree/master/examples/imagenet">Training ImageNet in
                PyTorch</a> /
            <a target="_blank" href="https://developer.nvidia.com/automatic-mixed-precision">Introduction</a> /
            <a target="_blank" href="https://nvidia.github.io/apex/amp.html">Documentation</a> /
            <a target="_blank" href="https://github.com/NVIDIA/apex/tree/master/apex/amp">Github</a>
            </br> </br>

            <b>NVIDIA Data Loading Library (DALI) for faster data loading:</b>
            <a target="_blank" href="https://developer.nvidia.com/DALI">Introduction</a> /
            <a target="_blank"
                href="https://docs.nvidia.com/deeplearning/sdk/dali-developer-guide/docs/index.html">Documentation</a> /
            <a target="_blank" href="https://github.com/NVIDIA/DALI">Github</a>
        </div>
    </div>
    </br>

    <div class="section" id="model_zoo">
        <div class="section_header">AMP Model Zoo</div>
        <p>
            Below are code repositories which have used AMP to train their models. Please refer to their respective
            READMEs
            to activate AMP.</br>
            These repos can serve as a guide for using AMP in your project.
        </p>
        <table align="center" style="width:100%">
            <tbody>
                <tr>
                    <td>ImageNet Classification</td>
                    <td><a href="https://github.com/NVIDIA/apex/tree/master/examples/imagenet"
                            target="_blank">https://github.com/NVIDIA/apex/tree/master/examples/imagenet</td>
                </tr>
                <tr>
                    <td>Semantic Segmentation</td>
                    <td><a href="https://github.com/NVIDIA/semantic-segmentation"
                            target="_blank">https://github.com/NVIDIA/semantic-segmentation</td>
                </tr>
                <tr>
                    <td>Mask R-CNN</td>
                    <td><a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Segmentation/MaskRCNN"
                            target="_blank">https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Segmentation/MaskRCNN
                    </td>
                </tr>
                <tr>
                    <td>SSD Detection</td>
                    <td><a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Detection/SSD"
                            target="_blank">https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Detection/SSD
                    </td>
                </tr>
                <tr>
                    <td>Vid2Vid</td>
                    <td><a href="https://github.com/NVIDIA/vid2vid" target="_blank">https://github.com/NVIDIA/vid2vid
                    </td>
                </tr>
                <tr>
                    <td>Pix2PixHD</td>
                    <td><a href="https://github.com/NVIDIA/pix2pixHD"
                            target="_blank">https://github.com/NVIDIA/pix2pixHD
                    </td>
                </tr>
                <tr>
                    <td>Image Inpainting</td>
                    <td><a href="https://github.com/NVIDIA/partialconv#mixed-precision-training-with-amp-for-image-inpainting"
                            target="_blank">https://github.com/NVIDIA/partialconv#mixed-precision-training-with-amp-for-image-inpainting
                    </td>
                </tr>
                <tr>
                    <td>Language Modeling</td>
                    <td><a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/LanguageModeling/"
                            target="_blank">https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/LanguageModeling/
                    </td>
                </tr>
                <tr>
                    <td>All TensorFlow links</td>
                    <td><a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/TensorFlow"
                            target="_blank">https://github.com/NVIDIA/DeepLearningExamples/tree/master/TensorFlow
                    </td>
                </tr>
                <tr>
                    <td>All PyTorch links</td>
                    <td><a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch"
                            target="_blank">https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch
                    </td>
                </tr>
            </tbody>
        </table>
    </div>
    </br>

    <div class="section">
        <div class="section_header">Organizers</div>
        </br>
        <table align="center" class="noborder">
            <tbody>


                <tr>
                    <td style="width: 15%;"><img class="pic" src="imgs/ArunMallya.jpg" alt="Arun Mallya"> </td>
                    <td style="text-align: left;">
                        <a href="https://arunmallya.github.io/" target="_blank"><b>Arun Mallya</b></a> is a Research
                        Scientist at NVIDIA Research. He obtained his Ph.D. from the University of
                        Illinois at Urbana-Champaign in 2018, with a focus on performing multiple tasks efficiently with
                        a single deep network. He holds a B.Tech. in Computer Science and Engineering from the Indian
                        Institute of Technology - Kharagpur (2012), an MS in Computer Science from the University of
                        Illinois at Urbana-Champaign (2014). His current interests are on making neural networks faster,
                        better, and more compact.
                    </td>
                </tr>

                <tr>
                    <td style="width: 15%;"><img class="pic" src="imgs/PauliusM.jpeg" alt="Paulius Micikevicius"></td>
                    <td style="text-align: left;">
                        <b>Paulius Micikevicius</b> works in compute architecture at NVIDIA on accelerating DNN training
                        and
                        inference through reduced arithmetic and other optimization techniques. In his previous roles at
                        NVIDIA Paulius focused on parallelizing various compute workloads for GPUs, including DL,
                        computer vision, scientific, and engineering applications. He also worked worked on developer
                        education, connecting chip architecture details to software optimization techniques, resulting
                        some of the highest rated and attended GPU Technology Conference talks. Paulius has also worked
                        on perception while at a self-driving car company Zoox and as an assistant professor of Computer
                        Science at Armstrong Atlantic State University. He holds a PhD in Computer Science from the
                        University of Central Florida.
                    </td>
                </tr>

                <tr>
                    <td style="width: 15%;"><img class="pic" src="imgs/CarlCase.jpg" alt="Carl Case"></td>
                    <td style="text-align: left;">
                        <b>Carl Case</b> is a senior architect in compute architecture at NVIDIA, where he works on
                        reduced-precision arithmetic for training deep neural networks. His focus is optimizing the
                        entire stack of deep learning training - from hardware to high-level software - to accelerate
                        the pace of AI development. Previously, he worked as a machine learning researcher on Deep
                        Speech and its successor speech recognition systems at Baidu's Silicon Valley AI Lab. He holds
                        bachelor's and master's degrees in computer science from Stanford University.
                    </td>
                </tr>

                <tr>
                    <td style="width: 15%;"><img class="pic" src="imgs/PavloMolchanov.jpg" alt="Pavlo Molchanov"> </td>
                    <td style="text-align: left;">
                        Pavlo Molchanov obtained PhD from Tampere University of Technology, Finland in the area of
                        signal processing in 2014. His dissertation was focused on designing automatic target
                        recognition systems for radars. Since 2015 he is with the Learning and Perception Research team
                        at NVIDIA, currently holding a senior research scientist position. His research is focused on
                        methods for neural network acceleration, and designing novel systems for human-computer
                        interaction and human understanding. For network acceleration, he is interested in neural
                        network pruning methods and conditional inference. For human understanding, he is working on
                        landmark estimation, gesture recognition, hand pose estimation. He received the EuRAD best paper
                        award in 2011 and EuRAD young engineer award in 2013.
                    </td>
                </tr>

                <tr>
                    <td style="width: 15%;"><img class="pic" src="imgs/KaranSapra.jpg" alt="Karan Sapra"></td>
                    <td style="text-align: left;">
                        <a href="https://karansapra.github.io/" target="_blank"><b>Karan Sapra</b></a>
                        is a research scientist at NVIDIA in Santa Clara, US. He obtained his PhD.
                        from Clemson University in 2018. During his PhD studies, he was an intern at Oak Ridge National
                        Lab in 2015. His research interest lies in using deep learning for computer vision and computer
                        graphics. During his PhD. he has also worked on various other research areas such as Peer2peer
                        (P2P) networks, computer networking and security, and high performance computing (HPC)
                    </td>
                </tr>

                <tr>
                    <td style="width: 15%;"><img class="pic" src="imgs/GuilinLiu.jpg" alt="Guilin Liu"></td>
                    <td style="text-align: left;">
                        <a href="https://liuguilin1225.github.io/" target="_blank"><b>Guilin Liu</b></a> is a senior
                        research
                        scientist at NVIDIA in Santa Clara, US. He obtained
                        his Ph.D. from George Mason University in 2017. During his P.h.D study, he as an intern at Adobe
                        Research in 2016. He received his B.E. from Wuhan University in 2012. His research interest lies
                        in the intersection among deep learning, computer vision and graphics. His recent research
                        interest focus on using deep learning for image processing and estimating physical properties
                        from images. His works have been published at ICCV, CVPR, ECCV, NeurIPS, IROS etc and featured
                        in some mainstream media outlets including Fortune, Yahoo Finance, VentureBeat etc.
                    </td>
                </tr>

                <tr>
                    <td style="width: 15%;"><img class="pic" src="imgs/TingChunWang.jpg" alt="Ting-Chun Wang"></td>
                    <td style="text-align: left;">
                        <a href="https://tcwang0509.github.io/" target="_blank"><b>Ting-Chun Wang</b></a> is a research
                        scientist at NVIDIA in Santa Clara, US. He obtained his Ph.D.
                        from
                        University of California, Berkeley, department of EECS, advised by Professor Ravi Ramamoorthi
                        and Alexei A. Efros. He received his B.E from National Taiwan University. He is a recipient of
                        the Berkeley Fellowship. His research interests include computer vision, machine learning and
                        computer graphics, particularly the intersections of all three. His recent research focus is on
                        using generative adversarial models to synthesize realistic images and videos, with applications
                        to rendering, visual manipulations and beyond.
                    </td>
                </tr>

                <tr>
                    <td style="width: 15%;"><img class="pic" src="imgs/MingYuLiu.jpg" alt="Ming-Yu Liu"> </td>
                    <td style="text-align: left;">
                        <a href="http://mingyuliu.net/" target="_blank"><b>Ming-Yu Liu</b></a> is a principal research
                        scientist at NVIDIA Research. Before joining NVIDIA in
                        2016,
                        he
                        was a principal research scientist at Mitsubishi Electric Research Labs (MERL). He earned his
                        Ph.D.
                        from the Department of Electrical and Computer Engineering at the University of Maryland College
                        Park in 2012. He is a recipient of the R&D 100 Award by R&D Magazine for his robotic bin picking
                        system in 2014. His semantic image synthesis paper and scene understanding paper are in the best
                        paper finalist in the 2019 CVPR and 2015 RSS conferences, respectively. In SIGGRAPH 2019, he won
                        the
                        Best in Show Award and Audience Choice Award in the Real Time Live show for his image synthesis
                        work. His research focus is on generative image modeling. His research goal is to enable
                        machines
                        human-like imagination capability.
                    </td>
                </tr>
            </tbody>
        </table>
    </div>

    </br></br></br></br></br></br></br></br>
</body>

</html>
